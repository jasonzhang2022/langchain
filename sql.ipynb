{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7960b753-925f-47bb-909b-f05cd571c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f8139f-4ee2-4893-b2d2-dd0295bd5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///../tmp/Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de15d0a-2841-4f56-b6e1-ecd46016e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(db.get_table_info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df31dcc9-535b-4ace-8c59-0cf9fad7cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155231e-7719-46d1-a28a-5ac36e9e85e3",
   "metadata": {},
   "source": [
    "## A basic query session\n",
    "\n",
    "1. We need to construct a query first from natural langugage. To construt a query, we need to give the model the sql dialect, and table information.\n",
    "2.  We execute the query using provided tool.\n",
    "3.  We give the question, table information, and  query result and ask the LLM to output a nautural langaueg  output.\n",
    "\n",
    "First implementation will using chain so we have fine control the execution flow.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c356a071-dab7-4929-9b67-82a3ef6a76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one.\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "q2q_template = PromptTemplate.from_template(\n",
    "    \"\"\"system\n",
    "\n",
    "Given an input question, create a syntactically correct {dialect} query to run to help find the answer.\n",
    "\n",
    "Unless the user specifies in his question a specific number of examples they wish to obtain, \n",
    "always limit your query to at most {top_k} results. \n",
    "\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "\n",
    "\n",
    "Never query for all the columns from a specific table, \n",
    "only ask for a the few relevant columns given the question.\n",
    "\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema description.\n",
    "Be careful to not query for columns that do not exist. \n",
    "Also, pay attention to which column is in which table.\n",
    "\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}\n",
    "\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Query is: \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "#since we don't expose the state to LLM for reasoning, we don't need detailed description.\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "def question_to_query(state:State):\n",
    "    \"\"\"Generate SQL query to fetch information based  on the question and database schema.\"\"\"\n",
    "    question = state['question']\n",
    "    prompt = q2q_template.invoke({\n",
    "        \"top_k\":10,\n",
    "        \"dialect\": db.dialect,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": question\n",
    "    })\n",
    "\n",
    "    ## The output for this turn\n",
    "    class QueryResult(TypedDict):\n",
    "        query: Annotated[str, ..., \"thq SQL query for the question\"]\n",
    "\n",
    "    llm1 = llm.with_structured_output(QueryResult)\n",
    "    resp = llm1.invoke(prompt)\n",
    "    return resp\n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "def execute_query(state:State):\n",
    "    \"\"\"Execute the provided query.\"\"\"\n",
    "    sql_executor = QuerySQLDatabaseTool(db=db)\n",
    "    return {'result': sql_executor.invoke(state['query'])}\n",
    "\n",
    "def generate_answer(state:State):\n",
    "    \"\"\"Generate the answer for original question from the query result.\"\"\"\n",
    "    prompt =(\n",
    "        \"The user asks the question:\\n \"\n",
    "        f\"{state['question']}\\n\"\n",
    "        \"We first convert the question into a query and execute the query against a database.\"\n",
    "        \" Here is the result from this query:\\n\"\n",
    "        f\"{state['result']}\\n\"\n",
    "        \"Could you please formulate an answer based on the question and query result?\"\n",
    "        \"Please only show the short answer. Don't give context and where the result comes from.\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'answer': response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf787ad-8626-4b6d-9983-7496a54432a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we build a chain to execute the code\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "builder = StateGraph(State).add_sequence([question_to_query, execute_query, generate_answer])\n",
    "builder.set_entry_point(\"question_to_query\")\n",
    "graph=builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c6f5a8-889e-4278-90ec-2165b3a1f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question_to_query': {'query': 'SELECT count(*) FROM Employee'}}\n",
      "{'execute_query': {'result': '[(8,)]'}}\n",
      "{'generate_answer': {'answer': '8\\n'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({'question': \"How many employees do we have?\"}, stream_mode=\"updates\"):\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4067f6-bdc6-4a6a-aa3c-d8d6860d2d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question_to_query': {'query': 'SELECT count(*) FROM Employee'}}\n",
      "{'__interrupt__': ()}\n",
      "==========Continue the invocation after interrupt\n",
      "{'execute_query': {'result': '[(8,)]'}}\n",
      "{'generate_answer': {'answer': '8\\n'}}\n"
     ]
    }
   ],
   "source": [
    "builder1 = StateGraph(State).add_sequence([question_to_query, execute_query, generate_answer])\n",
    "builder1.set_entry_point(\"question_to_query\")\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "graph1 = builder1.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
    "config = {'configurable': {'thread_id': \"sql_jj1\"}}\n",
    "for step in graph1.stream({'question': 'How many employees do we have?'}, \n",
    "                          config=config,\n",
    "                          stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "\n",
    "print(\"==========Continue the invocation after interrupt\")\n",
    "for step in graph1.stream(None, \n",
    "                          config=config,\n",
    "                          stream_mode=\"updates\"):\n",
    "    print(step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679b0599-248d-4b04-88dd-2c9455b2666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql_agent_prompt_text = \"\"\"system\n",
    "\n",
    "You are an agent designed to interact with a SQL database.\n",
    "\n",
    "Given an input question, create a syntactically correct {dialect} query to run, \n",
    "then look at the results of the query and return the answer.\n",
    "\n",
    "Unless the user specifies a specific number of examples they wish to obtain, \n",
    "always limit your query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given \n",
    "the question.\n",
    "\n",
    "You have access to tools for interacting with the database.\n",
    "\n",
    "Only use the below tools. Only use the information returned by the below tools to \n",
    "construct your final answer.\n",
    "\n",
    "You MUST double check your query before executing it. If you \n",
    "get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "\n",
    "Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\"\n",
    "\n",
    "sql_agent_prompt_template = PromptTemplate.from_template(sql_agent_prompt_text)\n",
    "sql_agent_prompt = sql_agent_prompt_template.invoke({\n",
    "    'dialect': db.dialect,\n",
    "    'top_k':10\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a61372-bf0a-4cf3-9e82-801d2eecffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "tools  = toolkit.get_tools();\n",
    "\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "question=\"Which country's customers spent the most?\"\n",
    "for step in agent.stream(\n",
    "    {'messages': [{'role': 'system', 'content': sql_agent_prompt.text}, \n",
    "                  {'role': 'user', 'content': question}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
